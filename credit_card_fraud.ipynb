{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sQFq-jraBjN"
      },
      "outputs": [],
      "source": [
        "#importing package related to project\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading csv file in dataframe or loading data\n",
        "df=pd.read_csv('creditcard.csv')"
      ],
      "metadata": {
        "id": "PtIYMKLLaYCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "8F6rPzlbrVaz",
        "outputId": "58419c90-4024-4000-e4a3-bb92ed37fe84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9b793f0-1aaf-4be1-833e-2866e51f895a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9b793f0-1aaf-4be1-833e-2866e51f895a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9b793f0-1aaf-4be1-833e-2866e51f895a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9b793f0-1aaf-4be1-833e-2866e51f895a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"columns name of data\",df.columns)\n",
        "print(\"shape of data is \",df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHT6e0g4iyiQ",
        "outputId": "012ca0cb-a10c-4835-baaf-170cdba20716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns name of data Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
            "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
            "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
            "       'Class'],\n",
            "      dtype='object')\n",
            "shape of data is  (284807, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of fraud in credit card',df['Class'].sum())\n",
        "print('percentage of fraud',(df['Class'].sum()/df.shape[0])*100)"
      ],
      "metadata": {
        "id": "D7MYpOUJpmJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedda838-813b-4ca6-df14-e81f688c089f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of fraud in credit card 492\n",
            "percentage of fraud 0.1727485630620034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "dCJcxAy2akt0",
        "outputId": "ef57554d-938f-48a1-96da-25d721b56877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e876cf6-7e1c-49a8-834c-c0c6d1377bf8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e876cf6-7e1c-49a8-834c-c0c6d1377bf8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e876cf6-7e1c-49a8-834c-c0c6d1377bf8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e876cf6-7e1c-49a8-834c-c0c6d1377bf8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for number of unique value in each column\n",
        "for v in df.keys():\n",
        "  print(v,df[v].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnsuzXKCam9G",
        "outputId": "07062581-baa4-4216-f8a6-d1d2a530208f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time 124592\n",
            "V1 275663\n",
            "V2 275663\n",
            "V3 275663\n",
            "V4 275663\n",
            "V5 275663\n",
            "V6 275663\n",
            "V7 275663\n",
            "V8 275663\n",
            "V9 275663\n",
            "V10 275663\n",
            "V11 275663\n",
            "V12 275663\n",
            "V13 275663\n",
            "V14 275663\n",
            "V15 275663\n",
            "V16 275663\n",
            "V17 275663\n",
            "V18 275663\n",
            "V19 275663\n",
            "V20 275663\n",
            "V21 275663\n",
            "V22 275663\n",
            "V23 275663\n",
            "V24 275663\n",
            "V25 275663\n",
            "V26 275663\n",
            "V27 275663\n",
            "V28 275663\n",
            "Amount 32767\n",
            "Class 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#since class is categorical variable changing it into categorical variable\n",
        "df['Class']=df['Class'].astype('category')"
      ],
      "metadata": {
        "id": "nMkteYalbDEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for data type of each variable in each columns\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diVZlFc8cLeZ",
        "outputId": "ddf053f8-394e-4ee6-e36b-0ad57b62b6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time       float64\n",
              "V1         float64\n",
              "V2         float64\n",
              "V3         float64\n",
              "V4         float64\n",
              "V5         float64\n",
              "V6         float64\n",
              "V7         float64\n",
              "V8         float64\n",
              "V9         float64\n",
              "V10        float64\n",
              "V11        float64\n",
              "V12        float64\n",
              "V13        float64\n",
              "V14        float64\n",
              "V15        float64\n",
              "V16        float64\n",
              "V17        float64\n",
              "V18        float64\n",
              "V19        float64\n",
              "V20        float64\n",
              "V21        float64\n",
              "V22        float64\n",
              "V23        float64\n",
              "V24        float64\n",
              "V25        float64\n",
              "V26        float64\n",
              "V27        float64\n",
              "V28        float64\n",
              "Amount     float64\n",
              "Class     category\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for null value in data\n",
        "if df.isnull().sum().sum()==0:\n",
        "  print('no null value found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odHOmRbwesNS",
        "outputId": "2bfe8e10-e5fd-4532-a720-590defc3d0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no null value found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualising linear relation betweeen variable using heatmap\n",
        "sns.heatmap(df.corr(method='pearson'));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "C-2d-6S8hnLE",
        "outputId": "42c82ed8-9aa1-42cd-aa87-d13fc8ca8218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(method='kendall'));"
      ],
      "metadata": {
        "id": "jXQ9OQ16ffKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "38cd2e1a-fc4a-4d80-d567-e205d2aacf27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(method='spearman'));"
      ],
      "metadata": {
        "id": "Lf95FRplf858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "da0b5db5-e446-441f-923c-7ed526d1e24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAELCAYAAADJF31HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de7xdVXXvv7/zSE4e5I28EnmEgAJGMTGIXAVBCpVWtFcUrApWjNXL1YjW6kevtjwUpRWvreKNVsGKSEsLiTUQEaOgAoYIIiECAVPyICIQCEnI45w97h9rnbA5nLPn2Huvs7OyM775rE/2WWvsMed6jT3XXGP+psyMIAiCYPenY1dXIAiCICiGCOhBEARtQgT0IAiCNiECehAEQZsQAT0IgqBNiIAeBEHQJkRAD4IgKBhJ35L0mKR7h9guSV+RtFLSPZJeWUS5EdCDIAiK5wrg1Brb/xSYkS9zgcuLKDQCehAEQcGY2S3AkzVMTge+Yxm3AxMk7ddsuTUDuqTJku7Ol/WS1uafN0n6WrOFB0EQ7KEcAKyu+ntNvq4pumptNLMngFcASPo7YJOZ/UOzhXrZ8fjDNXUJbjnyk0kfv+ypuYsAXPyHW5M2Z+wzO2nzge1K2nx7ZPqh6MTtI5I2Px2xveb26TYy6cPDjyuPJ23OsClJm5VdfUmbZ0jbPFLZnLQ5VhOSNmu0I2lzzI70eXi8M2nC7zq2Jm1et6On5vbRlbRER5dDxuPukelr9Ce965M2p3Ttm7TZonR9HrH0sZmq2scG4POrvpfesQSpeFPNiL2nv5+sq6Sf+WY2v9k6NEs62g2CpBOAj5nZn+WB/mDgEODFwEeAV5P1Ea0F/tzMdkiaBXwJGAs8DpxjZo82vQdBEARFUEk3KPrJg3czAXwtMK3q76n5uqYoqg99OnAi8Cbgu8ASM3sZ8CxwmqRu4J+At5rZLOBbwMUFlR0EQdA8VvEvzbMQeHee7fJq4OkiGrgNtdAH4Ya8Ff5boBO4MV//W+Ag4HDgKOAmSeQ20ToPgqA8VAoJ1ABIuho4AZgiaQ3wWaAbwMy+DiwC3gisBLYA7ymi3KIC+jYAM6tI2mHPafJW8jIELDezY1OOJM0l75v62j9exLnvPqugKgZBEAyNFdPyzn1ZzcCVx8j/VViBOUUF9BT3A3tLOtbMbsu7YA4zs+UDDav7pup5SREEQdAUBbbQdxUtCehmtl3SW4GvSBqfl/tl4AUBPQiCYJfQl858Kjsq84xFN+/z9pqVe93yzyd9HHr4m5M22xwn8otjZiVtftG9LWnT7XgP/UDf00mbCrXP2wd3TE762N+RTvfT7tFJG88VNNbR+PljZ9rT+Eo6O83TSlndkc5o6CZd1pRK+nzeXHN8ScYRHeNrbu9x1GV2+nSy3JG2OM5xjDc50ilWKX0/rK1sSdoc1DE2afPPq65pOm1x+6o7/WmLB81uurzhoFVdLkEQBOUmulyCIAjagyJfiu4qIqAHQRBAtNCDIAjahmihB0EQtAltkOVSmHyupCWSThmwbp6kGyTdJml5LuT+9qLKDIIgKIxKxb+UlMLSFvMRnsea2Xuq1t0OfBx41MwelLQ/sAx4qZk9lfJ54YF/WbNy39z022S9Vt5/fdLmild8Jmnzot70SZy5zx+TNp97Oq0E+PmXPpa0+cZ902puX6/epI8HKxuTNq/WxKTNJEea2zZHktckhzbSRoe6YY/jfnvckSLZ6UgV7HMkbY61tJ/fddRWzxxDese3ONQqX2xpBUmPEuX0SnfSZuoOxzF2xJ+3PfmzpE3v9rVNpxFuu/cmdzAcedTJpUxbLHKCi2vJhLhGAEg6CNgfuNXMHgQws3XAY8DeBZYbBEHQPG3QQi8soJvZk8CvyGRzAc4E/q1K1wVJc4ARwENFlRsEQVAEZn3upawUPQXd1WSBnPz/q/s35NMr/SvwHmuHhM8gCNqLvl7/UlKKDugLgJPyGaxHm9kyAEnjgB8Cn8rnzxsSSXMl3Snpzjs3rSy4ekEQBEPQWj30YaHQgG5mm4AlZBNYXA2Q96lfRzYh6rUOH/PNbLaZzZ499tAiqxcEQTA0lT7/UlKKbqFDFshfznPdLW8DXgecUzXh9CuGodwgCILGaYMWeqnVFnt6XlyzchN6xiR9XDg2rZJ4zt0XJG2+cXQ6tXEBTyRtPry9tqoewOJRSRP+5NnaWVO3jUpnVW0mfWHO6EuPPVvVmW6xTLR02t0DejZpM6svfXBWO+rT5UhJ7HWkJI6ydJtoxo50WfeOSJ+LcYmy7iOtXPgS0sevx5Fm+YxjAuiZ2zwpnen9XtqTvnY+9d9XNZ1GuPX2a9zBsOfVby9l2mKMFA2C3YBUMA8KoMQtby8R0IMgCAB6y5u94iUCehAEAZQ6v9xLPMcFQRBA4SNFJZ0q6X5JKyV9YpDtL841sO7Kda7e2OwuREAPgiCAQrNcJHUCXyUbOX8EcJakIwaYfZpsNP3RZAMxv9bsLkSXSxAEARSt0TIHWGlmDwNI+j5wOnBflY0B4/LP44F1zRZaaECXtAS4xMwWV62bBxxuZh/IR4zeB1xvZuel/J2xz+ya20/uTU9gPN6hkuhJSXzfXenUxi2vTPtZmxap43BHV96yntoZViMMDkmmy3WwPnEFPN6RzuR6zdZ0BtevE/UFeP2OdErdRsczZYcjJXHfvrQjj0LkJkf63kPdaZt9HZNNb0yUdRijXBNb70ikY45yJO+tdUyyvawnvU9jLR2CtjmOcSEUm+VyALC66u81wDEDbP4O+JGk/w2MAd7QbKHDqeXST7Wmy4XALQWXGQxCOpiTDOZBeUgFc6CQYL5HU4eWS7VESb7MbaDEs4ArzGwq8EbgXyU1FZOLvqWvBS6SNMLMtldL6EqaBewD3AjUbnoHQRC0mjq6XMxsPjC/hslaoHrSgqn5umreC5ya+7tNUg8whUxivCGK1nIZVEIXEPCPwMeKLC8IgqAwis1yWQrMkHRwrmd1JrBwgM0jwEkAkl4K9ADpWXJqMFxaLgMldD8ILDKzNcNQXhAEQfMUmOViZr3AecBiYAVZNstySRdIelNu9lHgfZJ+QxYnz7EmtViGoxd1AXBZtYSupPOB10r6IDAWGCFpk5kNlps5F5gLcMykVzBj7MHDUMUgCIIBFDwTkZktAhYNWPeZqs/3AccVWWbhAd3MNuXZLjsldM3sL/u3SzoHmD1YMM9td/ZNvevAv4g3OEEQtIYST1zhZbgGFg2U0A2CICg3IZ87vPxyv/9Zs3JXjkz/Hn1i/FNJm79+Mv2gcrImJ20+/Ot0rvols/5P0uaDR6VfNXx++f5JmxTrbGvSZiZpieINSuckT3bI5zrStXmsI30zjXbIv95PWqr3UI/UrCNVcJzj/l/dWdtolGOf1mp70mYfRiRtHEMP2MtRH0fmLJuUPjg/3PrfSZu71v+iaTnbZ6+9yB0MR7310yGfGwRBUFoK7kPfFURAD4IgAChxb4WXCOhBEAQQLfQgCIK2oQ2yXCKgB0EQQFu00AtLW8yF2k8ZsG6epMtzIfcfSVoh6b5c4yUIgqA8mPmXklJkC71/yP/iqnVnAh8HvgNcbGY3SRoLjunmgW8n0hJHOn6PPvf0hKTNh7enU+o8sreelMRPLLswafOameckbRa/qrZ08rfvmlZzO8Chlk5J9JyokUofP4/M7KMOSdYRjjTBPofNQepJ2kzpKyY1z3MMX5SQz/W0vDYpfTv/N+lU1emkj83TjtzGab3pg9PVkd6zy6z5FF0X0UJ/HtcCp+VCNFQpLT4BdJnZTZCNJDWzLQWWGwRB0DwFT0G3KygsoNdQWpwBPCXpP/O58y7Np2cKgiAoDdbX517KynBOcNGvtNgFvJZMOvdVwCHAOQWXGwRB0BzRQn8BC4CTqpUWyaZeutvMHs4lJa8HXjmUg+qZQH73zMMFVy8IgmAI2kDLpegJLjYBz1NaJBN6nyBp7/zvE3n+RKkDfcw3s9lmNvslex1SZPWCIAiGpmL+paQM1wQXO5UWzayPrLvlZkm/JZu96BvDUG4QBEHjtEGXy3DooV8Pz88byzNcZtbr68TttZXhvt35RNLH945Kq+pduGK/pM3hjvcgHpVET0riL++5Imkz/bDTa24/bdw+SR+rK5uTNsdpYtJmo0Mxb6RDnW9GX/pyXNWZPhFrtC1ps9Xx2Ly5M61MOMWhIjlze7qspT3Nt60erGxK2hytcUmbzY7z6VHPvKsrrf54VF/6GP94VDpn+ISkhYMSB2ovMVI0CIIAoMTZK14ioAdBEECp+8a9REAPgiCAUmeveBmuKeiCIAh2LwrOcpF0qqT7Ja2UNOgcypLelutbLZf0vWZ3IVroQRAEgBX4UjQfDf9V4GSysThLJS00s/uqbGYAnwSOM7MNkl7UbLnRQg+CIICiW+hzgJX5gMrtwPeBgalp7wO+amYbAMzssWZ3odAWuqQlwCVmtrhq3TzgcOAZ4DSyH5GbgA9bYobqn46onfZU6Usf2G/cl1Yd/JOt6bfby3rSZXkmbk6pJEI6JRHgoQcWJG2+mFB/3NaRngR5L8eL/2l96XbBjd1pPbaJGp20GW3psl7am1YLdAgB4hBbTE7uDHDvyHSK3zTH3AobEm6O1XgmJs7X6q70dbyVtM02h81bnk0fwDWOCDTGochYCMVmuRwArK76ew1wzACbwwAk/QLoBP7OzG5sptDh1HLpp1/T5TiyXPSjyDRdji+47KCKVDAPdi9SwRxIBvMgQR0Di6olSvJlbgMldpGJF54AnAV8Q1Ja7zvhsEiuBS6SNMLMtldJ6O4AeoARZIOOuoE/FFx2EARB49SRtmhm84H5NUzWAtXdA1PzddWsAe4wsx3A7yU9QBbgl7orMoCitVwGldA1s9vINF4ezZfFZraiyLKDIAiaolhxrqXADEkH53NEnAksHGBzPfkgV0lTyLpgmlIkHC4tl+dJ6Eo6FHgp2a/UAcCJkl47DGUHQRA0RoEvRXNl2fPIZnBbQdawXS7pAklvys0WA09Iuo+swfs3ZpbWM6nBcKQtLgAuq5bQlfQ3wO25GiOSbgCOBW4d+OW8L2ouwGsnvZKXhuJiEAQtwHqLfQlhZouARQPWfabqswHn50shFN5CH0JC9xHgeEldkrrJXogO2uVSLZ8bwTwIgpYR8rlD8jwJXbKXpQ8BvwV+A/zGzH4wTGUHQRDUTxtMcDEsI0UHSujmmujvr9fPdBtZc/spOyYnffysJ53gu3lU+nftJdvTObV3p5VA+fZd6bx4j/RtKi3x48suTPrwSPnuP2Jq0maCIw/9ANU+lwB/LEiG96FuhzQuaZuJDonYsY68eE/O9oqu2o/7HrnaAarVgzLS0bgc75jyd7TjPPyqJx1eHnFIHffQoimIS9zy9hJD/4MgCACLgB4EQdAmREAPgiBoEwrOctkVREAPgiCAaKEHQRC0CwmtwN2CutMWJS2RdMqAdfMkXS7pRklPSfqvAdsPlnRHLvR+TT4UNgiCoDy0QR56Iy30/qH9i6vWnQl8nEx0azQvTFH8AnCZmX1f0teB9wKXN1D289i/Y2vS5sFK2ubwjvRM6Ou70r996yxd1qE2JmmzurI5aZOSvvWkJP7yniuSNv/8ys8kbX7QnZ5tfqZjvzscaXeeGem3O9IE/2jpGem7HamWB1TSKXVrO9Kps2MSbauxjjRBD54M6g5HvNrQkfbU5ajzdkeNXtaXPg+FUOJA7aWRgUXXAqf1t7KrFBVvNbObyXTPdyJJwIn59wCuBN7cYH2DIAiGBauYeykrdQf0GoqKQ+3lZOCpXKwGMsnIA+otNwiCYFjpNf9SUhod+v8CRcViqhMEQbBr2CNb6DkLgJOqFRVr2D4BTJDU318/mND7TqpnArlj04MNVi8IgqBO2uClaEMBfQhFxaFsLbd9a77qbLIfhKHsd6otHjN2RiPVC4IgqJ9KHUtJaUZtcaCiIpJuBf6drPW+piq98W+B8yWtJOtT/5cmyg2CICicduhyUZmT6f9k2qk1K3dix5SkD08K25RKOr3qcUcu1whH2t04x6/7046f2b0SftY7ZqOfXEkXdN6vL0ja3HrkJ5I2N49KZ8jOSWd98quetM2Le9P75WnJeBpinsmbRzlusU1q/j7scaQJbimgHC87HJmWFcf96RmQ//lV32s6r/PJtxzvPjiTrvtZMXmkBRMjRYMgCKDUXSleIqAHQRBQ6nkr3ERAD4IggLZooQ/XFHRBEAS7FUXPQCfpVEn35xpWQ75okvQ/JZmk2c3uQwT0IAgCKDRtUVIn8FWyEfVHAGdJOmIQu72ADwN3FLELEdCDIAiASq9/cTAHWGlmD5vZduD7wOmD2F1IJl7oyPFKU3cfuqQlwCVmtrhq3TzgcOBg4NXAz83sz6q2XwXMBnaQ6cC838x2pMo6w2qnJT7uqO8kR0riqs50YtRrtqb93NbjmOTYMQHvRoei4LTExMyeiZs9Kokvd6Qkvnb5JUmbviM/mbS5yTFZ9w5HmtvSrrSS4vrKs0mbwzr2Strsa+lb6FlHgpsn5XBzIuVws4wD+mr72epIs/SoXnpy9kY7WrJbHI5alWpZ8EvRA4DVVX+vAY6pNshH2k8zsx9K+psiCm2khV6t49JPv57LpcC7BvnOVcBLgJcBo4BzGyg3CPZYUsEcSAbzIIHJvVRLlOTL3HqKktQBfAn4aJG70EiWy7XARZJGmNn2AfK5JumEgV8ws0X9nyX9ikzPJQiCoDTU00I3s/nA/Boma4FpVX8P1LDaCzgK+GmmMM6+wEJJbzKzO/01eT6tkM/diaRushb8jfWWGwRBMJxYRe7FwVJgRj5b2wiyOLlwZ1lmT5vZFDM7yMwOAm4Hmgrm0Hr53K8Bt5jZrQ2WGwRBMCwUmbaYz/9wHtnMbivIGr3LJV0g6U3DtQ+NDixaAFzmlM8FQNJngb154fR0A+3mAnMB3jlhDq8bE4qLQRAMP5WC30HkXc2LBqwbdE5HMzuhiDKHXT4XQNK5wCnAWWa1f9+q5XMjmAdB0CoK7nLZJbRKPvfrwD7AbZLulpSeeTgIgqCFmPmXstKwlouZXc+AdFQze+0Qtg2Vs7Krdn741L50Uu02x4/pREv7+XVP+ixOtvTvo0cmdaQjJ/nG7i01tx/gmLF+po1J2tzs0H715JifsPzzSZvrZqdz3g+yEUmbKaTP51TH8XEoJrPNkRd/YG/6fC7vrn2tT3Bco+s703Xx5Jh78IwHMBVT1mjH/VAEZW55ewlxriAIAiKgB0EQtA1FvxTdFURAD4IgAKxFXTvDSQT0IAgCYoKLIAiCtqHSBi30utMWJS2pSkfsXzdP0uWSbpT0lKT/GuK7X5GUlvgLgiBoMWZyL2WlkRZ6/7D/xVXrzgQ+DnQDoxlkNGg+G8fEegp6JjHf9x87079HBzumHr+lOy2l+vodo5I2TzikSR/tSEv1zuhLn5aJGl1z+x8dEryeFLY5W9PpaR7ZW09K4v+9My3De9ms9BCGlUpLS28xx3lIHGOACZX0vv+ie1vSZk5v7TTKdY6UxJGO8+lJm53oyPbY5Ihpa5VUyGaKI6PZcVsVQjtkuTQysOha4LRccIYBaos3A88M/EI+e8elZEE/CIKgdFT65F7KSqvUFs8DFprZo/VXMQiCYPipmNxLWRl2tUVJ+wNnAP/UYFlBEATDTjv0oTca0BeQ6bV41BaPBg4FVkpaBYyWtHIo4+qZQO575uEGqxcEQVAf7aDlMuxqi2b2QzPbt0rIfYuZHVrDfqfa4hF7HdJI9YIgCOpmT+5ygfrUFoMgCEpNO3S5tERtcYDNWG8Zj1Q219w+3ZEFudGR8zSrL52SuNHx0/dYRzpVcIQjtWxVZzqlbnRC2dGj2LjZkdr4q56kiUt5z6OS6ElJ/MiyC5I2/+jw45lJ3qPy95gjDfXYHWllx1TK62gTWxN17nZ0BYxz7JNHoTS913BwpTtp4wlAqzp6HVbN09cGaYsxUjQIdgNSwTxonjK3vL1EQA+CIKA9hv5HQA+CIABHx2H5aealaBAEQdtQdJaLpFMl3S9ppaQXaF9IOl/SfZLukXSzpAOb3YcI6EEQBECfyb2kyOVOvko2ov4I4CxJRwwwuwuYbWYzySRVvtjsPkRAD4IgAAy5FwdzgJVm9rCZbQe+D5z+vPLMlphZ/+TAtwNTm92HuvvQJS0BLjGzxVXr5gGHAwcDrwZ+bmZ/VrVdwEVkEgB9wOVm9pVUWcdqQu3KOzq9ehyi9Q8nJqMGnzKhJ82tz+FnjdLqfC/tTecTPtRde+e3O3oNp/em8z6Xdm1P2ngmbvaoJHpSEj/qSG3806M/kLQ5VXsnbTz7tW+vJ+0udSuKFYmJpDcqPXH6E53pG6LLcR1PdNisc6R0jnFMrL7FlSTZPJViO9EPAFZX/b0GOKaG/XuBG5ottFXyuecA04CXmFlF0osaKDeog1QwD3YvUsEc0sE8qE3F1/IGMokSYG7VqvlmNr+RciW9E5gNHN/I96tpJKBfC1wkaYSZbR8gn2uSThjkOx8A3mGWTfJkZo81WN8gCIJhwdmVktlmwbtWAF9L1ojtZ2q+7nlIegPwKeB4M0s/midolXzudODtuejWDZJm1F/VIAiC4aNSx+JgKTBD0sH53BFnAgurDSQdDfw/4E1FNXKHXT43ZySw1cxmA98gE/UKgiAoDX3IvaQws16yeSAWAyvIGr3LJV0g6U252aXAWODfJd0taeEQ7tw0OrBoAXCZUz4XshcC/5l/vg749lCG1X1Tp0+aw6vGDinMGARBUBhFv3Uys0XAogHrPlP1+Q0FFzn88rk51wOvzz8fDzxQw/dO+dwI5kEQtIqC0xZ3Cc0M/b+arLXd3/XSL5/7EmCspDXAe/P0xkuAqyR9BNgEnNtEuUEQBIXTBmKLrZHPNbOngNPqLWNNYtbwMUqnaU1U+iGky/GLu29f2s8dHVuSNgcpnT++1dIPf72JKm92PED+0dL54zMYnbRZX3k2aTNVaQnZLZZOzfPI3npyzG+46/KkzbtnnZ+0eU0lrQZ9e0/6Ou1IjAmYaGkfqWsCfNfxM47n9o2O8+BJo0wL7MIk0tdOEdSTtlhWQpwrCIIAn8Z72YmAHgRBAFQULfQgCIK2oB3kcyOgB0EQUHza4q4gAnoQBAHtkeVSdx66pCWSThmwbp6kyyXdKOkpSf81YPtJkn6dj4b6uaRIMA+CoFRUkHspK61SW7wcON3MVkj6IPBpMgXGmhyzo/ZM8fc7FAU7HQe/1/Gw5ZkJ/VBGJW2m9KUdbe6svd8AKTeeNLduRyqh5zH0sI69kjYdjg7KGUqnSHokij2yt56UxO8s+1LS5pJZ/ydp86gc6aGV2uditOP43dWZ1naa5LjlxzokbXc47gfPPeNRoxrZos5tx61ZehoZKXotcFouOMMAtcWbgWcG+Y4B4/LP44F1DZQbBEEwbBQszrVLqLuFbmZPSupXW1yAT23xXGCRpGeBjWSTYARBEJSGdshyaZXa4keAN5rZVDJhrvSzbBAEQQupyL+UlUYD+gLgJI/aoqS9gZeb2R35qmuA19Swn5vrpt/5080PNli9IAiC+miHLpdWqC1uAMZLOiz/+2QyfeChfO9UWzxhTMyDEQRBa2iHgN4StUVJ7wP+Q1KFLMD/VRPlBkEQFE47ZLm0Sm3xOrLgXxePJzLvplTSDxhbHapwoxxpWpscfnocKZKedK8pjpTD1YnZ2z2pZwdU0uVscMw7vK+lL6NtjldOExzn8zHHTPJTSFfao5LoSUn8xLILkzbLZn4saXNTd+3j86zSL+1GO/bb8+LPoz7aVzMHIsNzz2xz3Z+tibRlbnl7iZGiQbAb0A4ZGGWnHY5xBPQgCALKnb3iJQJ6EAQB7dHl0mjaYhAEQVvRV8fiQdKpku6XtFLSJwbZPlLSNfn2O/JR900RAT0IgoBiBxZJ6gS+Sjai/gjgLElHDDB7L7DBzA4FLgO+0Ow+REAPgiCg8Dz0OcBKM3vYzLYD3wdOH2BzOnBl/vlassGaTfXk192HLmkJcImZLa5aNw84BZhAJsLVB1xsZtfk2w8m26HJwDLgXflO1uR3HVtrbl9XSU/KfIpNStpM6U2a8FAirQxgnONMey6GmdvTVveOrJ2i5kkTXNuR3vEZlfQ0vs86LsEDHTMY/6I7rb137I60QuS+ven98kzc7FFJ9KQkzrrnH5I2v5+ZTpFc31X7GC6zTUkfJzIhaeNRxhzrSG2c6OibmDliY9Lm8a1pFdMiKDjL5QBgddXfa4BjhrIxs15JT5PFyMcbLbSRFnq1jks/ZwKfB95tZkcCpwJfltR/9XwBuCx/tNhA9qgRBIGTVDAPmqeCuZdqiZJ8mbur6w/Fy+c+CGBm64DHgL3zR4gT8+9B9ojx5uaqHQRBUCz1dLlUS5Tky/wB7tYC06r+npqvG9RGUheZtPgTzexD3QHdzJ4E+uVzYRD5XElzgBHAQ2SPEE+ZWf9z8BqyR40gCILSUHCWy1JghqSD88bvmcDCATYLgbPzz28FfpKQIU9SuHyupP2AfwXeY2btkNoZBMEeQJFZLnkD9jyymd1WkDV6l0u6QNKbcrN/ASZLWgmcD7wgtbFeGh1YtAC4bKB8rqRxwA+BT5nZ7bntE8AESV35Tg726LGTvC9qLsBxk47mJXsd0mAVgyAI/FQKfi1qZouARQPWfabq81bgjCLLLEw+N3+suA74jpldW2Vrue1b81Vnk/0gDOV7Z99UBPMgCFqF1bGUlWby0K8GXs5z3S1vA14HnCPp7nx5Rb7tb4Hz80eLyWSPGkEQBKVhj9ZDHyifa2bfBb47hO3DZIn2dfG6HT01t9/Tnc6R/h3pXOIJI9KHYV+HtGtK0hbgRQ4/S3vSNtMSqdYrutKvbsY4fs9dssEOedPl3en6zOlN55g/4ZDz9VzWHY521oxKuj4p2Vvw5Zi/9Z7aMrw7/v2ypI8FF69P2jguP1cf8WMd6Wv9D45ztbl3fNLmUHakHRVA0V0uu4IQ5wqCIMCv0VJmIqAHQRAQLfQgCIK2YfcP5xHQgyAIgHK/7PQSAT0IggCwNmij1522KGmJpFMGrJsn6Xt6x30AABGfSURBVAZJt0laLukeSW+v2n5VLvR+r6RvSUqnpwRBELSQXsy9lJVGWuj9w/4XV607E/g48KiZPShpf2CZpMVm9hRwFfDO3PZ7wLnA5amCRldqH7geh4QnjpnQx1n6d21jQbOTFyVAvyGxW5Mtvd9jHfX1pC1udthMcNRnXWfaj+f4rehOPzxPdNRntOO+3eK4BD1Kiam0xO4zPpL00XnxX6fLcdTXcRpcTOtNn61HutLnqovWtP/KG6b9DLvaYv73IsshE/aa2nzVgyAIiqMe+dyy0gq1RarWdwPvAm5stMJBEATDQTuMFG212uLXgFvM7NYGyw2CIBgWrI5/ZaXRgL6AbP47j9oi+bbPknXBnF/LcfVMIDdtWdlg9YIgCOpjj22h16O2mG87l2zO0bNSGunVaosnjz60keoFQRDUTR/mXspKq9QWvw7sA9yWr//MC90FQRDsOipm7qWstEptsaFyuhIHbvbWtI8f9aQld/5Aerb5IxmdtPm90n42KX0oHqykZ29/YyWlUlfMpMK9HWk/ExzPoOsduXAjHXV2iBsyrpJOSex1HJ67OtPnc7QjLXaZpc9nUinx4rl0JtpfN9799WQ5V7883Zb66KalSZt5E2YnbbY7jvEWRwfGiq7WBNDyhmk/MVI0CHYDUsE8aJ4ypyN6iYAeBEFAewz9j4AeBEFAubNXvMRzXBAEAdBHxb00g6RJkm6S9GD+/8RBbF4xlDZWLSKgB0EQ0NI89E8AN5vZDODm/O+BbAHebWZHAqcCX5Y0IeU4AnoQBAFgZu6lSU4Hrsw/Xwm8eZC6PDCUNlYt6u5Dl7QEuMTMFletm0c2cGgCMI5ser6LzeyaAd/9CvBXZjbWU9bdI2vnPXk02F5sI5I2fQ5POxwvTPYhXdZ/k861PFrjkjarE6lcIx3XXFF9hlsdkwF3OFISPcqO4xwKkU84Juvety/dlpnkuD08t/aJJBtWrsmbU0qJnpTEs35zQdJm9az0pNae87necR4O6Usf4w0drXlZ2cIsl33M7NH883qyMTpDMpQ21mC0Sj4XSbOBF/QVBUGQxiN7GzRHPQ0cSXOBuVWr5pvZ/KrtPwb2HeSrn6r+w8xMGrolU6WNdXZqlD00FtCvBS6SNMLMtg+Qz7W8kusk9T8iPCWpE7gUeAfwlgbKDIIgGFbqedmZB+/5Nba/Yahtkv4gaT8zezQP2I8NYTekNtZQtEo+9zxgYdVjRhAEQaloYR/6QuDs/PPZZGKHz6OWNlYthl0+N+9+OQP4pwbLCoIgGHZamOVyCXCypAeBN+R/I2m2pG/mNrW0sYak0YFFC4DLnPK5RwOHAislAYyWtNLMBpVSrO6b+rNJc5g1NhQXgyAYflo1UtTMngBOGmT9nWTTc9bUxqrFsMvnmtkPzWxfMzvIzA4CtgwVzHP7nfK5EcyDIGgVe+QUdFXUI58bBEFQalrYhz5stEQ+d8D3XDnoAD/prS0pekbHfkkf93fuSNocXEnnoY9ynMPHHPmy0+lJ2mxWupdua6KVMF7p5HBPeq8jxdyVk+xhYiXtZ5ujqC5HrvozjqbMWEsbdTn23XOcU7vuUB92yd56csw/vuzCpM2nZn8qabOJtHT1js70FfYihxxyETQ7pL8MhDhXEAQBlHriCi8R0IMgCIgJLoIgCNqGMr/s9BIBPQiCgAjoQRAEbUNfWiql9NSdtihpiaRTBqybJ+mGoQTZlXGxpAckrZD0oSIqHwRBUBRWx7+y0iq1xXOAacBLcjmAF3kKOqVrMLGy50jPpQ7THSmJTztkW9d2pFOwDqikD+fTjhy2yZZO09qWuKhGO1L3NnSkWySdDj+epEWP/PAmh6P0WYCJjjpvdJxzj8JhnyMzYqzjCD3mOBcp5k2YnbTxpJh6UhIvvvPipM07Z52ftJmiMUmbdR29SZsiKHN+uZeWqC0CHwDe0S//aGaDqosFQRDsKtqhD71VaovTgbdLujPvmpnRXLWDIAiKpR1Gig672mK+eiSw1cxmA98g04AJgiAoDXuylssC4CSn2iLAGuA/88/XATOHcixpbt6Sv3PpppUNVi8IgqA++qziXsrKsKst5lwPvD7/fDzwQA3fO9UWXxVqi0EQtIg9Nculn6vJAnh/10u/2uJkSefk684xs7vJBNyvkvQRsuSUc5soNwiCoHD2aC2XetQW89TF0+otY0sitexxtid9vGH7iKTNgY4Tuawn/TDjSXOb1ps2uqsrvV9veba2n1/1pE+tR5XQs0+jHU+gprSjtSpGGXOdI8V0ap8jNdSx75sc6Y8THbmWf3AICk7rrX0NbnfUd31n+mR5VBI9KYnfXfaldFnv/6ukzfnLJidtiqDMLW8vMVI0CHYDUsE8aJ49uoUeBEHQTkQLPQiCoE0oc/aKl3iOC4IgAMwq7qUZJE2SdJOkB/P/J9awHSdpjaR/9viOgB4EQUBLBxZ9ArjZzGYAN+d/D8WFwC1exxHQgyAIaOnQ/9OBK/PPVwJvHsxI0ixgH+BHXsd196FLWgJcYmaLq9bNA04BJgDjyETxLjaza/LtJwGXkv2AbCLLT08OA33EttbcvsG2Jevbaek0t7GOR6ixlj5UmxyTO3d1pH9Dj+pLp1quSVTnEaWPzXbHpLgHMDJps6WYOaKZ4jjGngt2jGNy5/RVAekjCNscaYszR2xM2mzuHZ+0eaSr9vna4jifh/Slj6Bn4maPSqInJXHs/0urgBw+6zNJmyJo4ZD+fczs0fzzerKg/TwkdQD/CLwTeIPXcavkcy8HTjezFZI+CHyaTFI3CAIHqWAeNE9fxX+MJc0F5latmm9m86u2/xgYTP/7edrEZmbSoK2CDwKLzGyNHGM4+mmVfK6RtdwBxgPrGig3CIJg2KgnbTEP3vNrbB+yVS3pD5L2M7NHczHDweTEjwVemzeAxwIjJG0ys1r97fUHdDN7UlK/fO4CfPK55wKLJD0LbAReXW+5QRAEw0kLZXEXAmeTSaKcTRZHB9blL/s/51Iqs1PBHFonn/sR4I1mNhX4NpAeExwEQdBCWpjlcglwsqQHyfrHLwGQNFvSN5tx3OjAogXAZR75XEl7Ay83szvy714D3DiU4+q+qWMmvYIZYw9usIpBEAR+WtVCN7MngJMGWX8ngwgXmtkVwBUe362Qz90AjJd0WP73ycCKGr53yudGMA+CoFVUzNxLWWmJfK6k9wH/IalCFuDT+UxBEAQtpB2G/qvM8+N98qB31KzcMw6Zz6+v+3nS5u/3OyFp45FS/cHWVUmby2z/pM2PR6WzpFO51uuVnil9hiMnea1DbtXDaIdUr4cnlT7nWxzXxcv60vn1njtjQ0fa6n9sTcsCG7WPz6ru9DWxoiu93+McOfqec7WuI319bSC934fbqKTNR5ddkLTpnnJI0xfYuDGHuIPhxs0PFzT6olhCnCsIgoCQzw2CIGgbQj43CIKgTYgWehAEQZtQ5veJXiKgB0EQAJU2yHKJgB4EQUB7tNDr0gDe1QswN/yUvy7hJ855GfzsicvuNsHF3LTJHuunTHUJP63xU6a6lNHPHsfuFtCDIAiCIYiAHgRB0CbsbgF9SEH58FOquoSf1vgpU13K6GePo9RaLkEQBIGf3a2FHgRBEAxBBPQgCII2IQJ6EARBm1DqgC5pH0n/IumG/O8jJL13V9crCIKgjJQ6oJPNo7cY6J8V4gFgXj0OJI2TNH2Q9TObqZikzzXwnRdL6sk/S9J7JP2TpA9IqkuGQdLrJB2efz5O0scknVbH97skvV/SjZLuyZcbJP21pPRsCs/56cz9XCjpuAHbPu3fo0F9P9DAd86TNCX/fKikWyQ9JekOSS+rw88hkr4l6SJJYyV9Q9K9kv5d0kF1+Cn1cW6HYxw8R6mzXCQtNbNXSbrLzI7O191tZq9wfv9twJeBx4Businxlubbfm1mr3T6+crAVcC7gO8AmNmHnH7uBeaY2RZJXwCmA9cDJ+Z+XFPzSfoyMIdMi2cx2YSzNwDHA3eZ2d84fFwNPAVcCazJV08FzgYmmdnbnXX5JjAa+BXZMfmZmZ2fb6vnGD/Dc5ME9c8GMxrYApiZjXP6WW5mR+affwh808yuk3QCcLGZHVfTwXN+biGbZnE88E7g28C/AX8C/KWZnej0U5rj3K7HOKhiV2sP1FqAnwKTgV/nf7+a7EL2fv9uYL/88xzgd8Bb8r/vqsPPauC7wLvJbsSzgT/2f67Dz31Vn5cBHVV//6YOP8vJbsjRZHO0js7XdwP3On080Mi2QWzvqfrcRZZD/J/AyDqP8VfIfiD3qVr3+waumfurPi8dqq4OP3dVfX5kqG2703Fu12Mcy3NL2btczgcWAtMl/YLsYvzfdXy/y8weBTCzXwGvBz4t6UP4pozs50jgceBU4CYzuxJ4xsyuzD97WS2pv9WxCpgGIGlyHT4ga00Z0K/32b8vFfzdaE9KOkPSTntJHZLeTvYj4WVEVaV6zWwu2Q/pT4CxXieWPeX8X+BqSR/K69XI4+O1kq6QdAhwnaR5kg6U9B7gkTr8VCQdJulVwGhJsyHrYgA66/BTmuPcxsc46GdX/6KkFrLWyJHAUUB3nd/9JTB9wLq9gJuBbQ3UZRawBPgYsKqB70/Lv38L8AOyG3oJcBdwUh1+vgD8HFgKXJr7+hTwI+DrTh8HAdeQPWk8kC+P5esOrqMu3wVOHWT9ucCOBo5RB/Ah4FZgXYPXzDnAHWQ/ws8A9wGfA8bX4eMk4H5gBfA/gP8AVubH6PQ6/JTuOLfbMY7luaXsfeidwGlkN8XOl4Zm9iXn9xcBnzOznw9Y3w28zcyucvr5KvA9M/uFJAEfBI41s3e6duT5fq4GngRmkO3TGrLHVre6vqSvAd8ju5HvUPbS9y1kraNr6/GV+5sMYGZP1PO94UTSfsDRZrZoV9eln/xF4AYz62vw+6U6zu14jPd0yt7l8gOylsBkspZ1/+JlMXCppFWSvijpaAAz2+EN5jkPAP8gaRVZ6/iX9QbzKj+XAouA44CHzeyOegMwWavmUuAaSV8ExpnZP5jZvzXgCzN7ojrISDq5Xh+D0YwfM3u0P9CUoT55nR43s756/SjPtBrkONeVaaUCMraqfQw4xi2vy2B+qo5xU1loeyy7+hGh1kIdL1gSfg4E/pasa+N3wGeBGQX5OWx39zOI30ea9RF+dtq+DVhH1t+9HHhV1bZft9JPmepSpJ9YnlvK3uXyBeBmM/tRgT6PBr4FzDSzhl+87O5+JC0cahNwopmNcZYbfmr7uRv4UzN7VNIcshf7n7QszW9nOm4r/JSpLkX6CZ6j7HOK3k72Fr0D2EF2M5k582X7UTZo50+BM8lexPwU+Lt6K9Nmfl5Llvu7aaBbshRPL+GnNs/LtJL0euC/JE2jvgyTIvyUqS5F+gn62dWPCLUW4PfATPIBUA18/2SyVut6svTHdwBjwo9BNhDp9UNsuyX8FOankEyrIvyUqS5F+onluaXsLfTVZANlGv21/iRZNshHzayenN89wc/vyZ56XoCZvS78FObnKWA/4KGq7z8j6VSyPuRW+ilTXYr0E+SUvQ/9CuAQstbStv715kxbDIZG0ofJumr2IxtufbWZ3RV+2tdPmepSpJ/gOcoe0D872Hoz+/tW16VdkXQg2U11JjCKLE/+ajOrS7Qp/DTk53tm9mCr/ZSpLkX6CUoe0IPWsrtn7oSf3bsuRfrZUynlwCJJ/5z//wNJCwcuu7p+7YQyedc/l3QVWdfW/cBfhJ/29VOmuhTpJyhpC13SRjMbJ+n4wbab2c9aXad2Q9lox7OAN5JJsn4fWGBmm8NPe/opU12K9BM8R1kDegwqGGYk/YQsU+Y/msm4CT+7j58y1aVIP8FzlDWgrwGGzGSJLJcgCIIXUtY89E4yjWelDIMgCIKMsrbQ3VOXBUEQBBmlzHIhWuZBEAR1U9YW+iQze3JX1yMIgmB3opQBPQiCIKifsna5BEEQBHUSAT0IgqBNiIAeBEHQJkRAD4IgaBMioAdBELQJ/x9eHlFedSLhvgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see from above no features is completely correlated to other some fetures are related but it is less so from here dimension reduction is not possible"
      ],
      "metadata": {
        "id": "b_INq-HW_gmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for duplicate sample\n",
        "print(df[df.duplicated(keep='first')].shape[0])"
      ],
      "metadata": {
        "id": "EeMgL79KileS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4461b9e-e441-407a-a7c1-af95b8afc868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see here 1081 duplicate sample so we can remove that sample from our data since it is not contribute in learning model"
      ],
      "metadata": {
        "id": "qcK9Xzi_2nri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(keep='first',inplace=True)\n",
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "4-lu3AylmvcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['Class'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "SalTOFVJ4c9c",
        "outputId": "289c0526-6f13-4294-fa1b-ca883c01d5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa304d1f280>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Class']].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uQzldjr5Cex",
        "outputId": "a5f84c5d-8ce2-4000-8d66-529dbeba6e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class\n",
              "0        283253\n",
              "1           473\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see from above. data is highly imbalanced we have to balance it \n",
        "here i have used under sampling algrithm and also over sampling algorithm"
      ],
      "metadata": {
        "id": "akfTdvNS5j0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data in training and test set\n",
        "X=df.iloc[:,:-1]\n",
        "y=df.iloc[:,-1]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0,stratify=y)"
      ],
      "metadata": {
        "id": "y0xgUJsoEcPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "random undersampling"
      ],
      "metadata": {
        "id": "xuNpXuAh73di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df[df['Class']==1]\n",
        "df0=df[df['Class']==0]\n",
        "#since df1 has more sample i have taken random sample from df1 to equate size of df0 and df1\n",
        "df0_sample=df0.sample(df1.shape[0])\n",
        "df_under1=pd.concat([df1,df0_sample],axis=0)\n",
        "X_under1=df_under1.iloc[:,:-1]\n",
        "y_under1=df_under1.iloc[:,-1]"
      ],
      "metadata": {
        "id": "4ULbTiqe5QVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "near miss undersampling using NearMiss-1 (selects examples from the majority class that have the smallest average distance to the three closest examples from the minority class)"
      ],
      "metadata": {
        "id": "mo7zko3wDSBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "undersample=NearMiss(version=1,n_neighbors=3)\n",
        "X_under2,y_under2=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "k8CEfnWLDsju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NearMiss-2: selects examples from the majority class that have the smallest average distance to the three furthest examples from the minority class"
      ],
      "metadata": {
        "id": "CNuoh-YBFaQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "undersample=NearMiss(version=2,n_neighbors=3)\n",
        "X_under3,y_under3=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "kMKnV7UVFHIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "involves selecting a given number of majority class examples for each example in the minority class that are closest"
      ],
      "metadata": {
        "id": "Aso7nbDdF8oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "undersample=NearMiss(version=3,n_neighbors=3)\n",
        "X_under4,y_under4=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "X8mMOD4rFHKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Condensed Nearest Neighbors, or CNN (undersampling technique that seeks a subset of a collection of samples that results in no loss in model performance, referred to as a minimal consistent set)"
      ],
      "metadata": {
        "id": "8TJ0DrJoH5yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "undersample=TomekLinks()\n",
        "X_under5,y_under5=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "CbogTwr1FHRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edited Nearest Neighbors Rule for Undersampling"
      ],
      "metadata": {
        "id": "E3KJkp8pkcl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "undersample = EditedNearestNeighbours(n_neighbors=3)\n",
        "X_under6,y_under6=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "qW8D5RwUJOVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Sided Selection for Undersampling"
      ],
      "metadata": {
        "id": "F8eDAFg-kt-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import OneSidedSelection\n",
        "undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n",
        "X_under7,y_under7=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "s3PnxpDtkpb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neighborhood Cleaning Rule for Undersampling"
      ],
      "metadata": {
        "id": "EMpYiqxVlER1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
        "undersample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
        "X_under8,y_under8=undersample.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "DhVl3XyqlFtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##oversampling"
      ],
      "metadata": {
        "id": "VBZ6wyMzlTIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive random over-sampling"
      ],
      "metadata": {
        "id": "i6s7sq-KvifH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "X_over1,y_over1=ros.fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "gw71utg7vlm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE first selects a minority class instance a at random and finds its k nearest minority class neighbors. The synthetic instance is then created by choosing one of the k nearest neighbors b at random and connecting a and b to form a line segment in the feature space. The synthetic instances are generated as a convex combination of the two chosen instances a and b\n",
        "\n",
        "ADASYN\n",
        "\n",
        "first of all, this impurity ratio is converted into a probability distribution by making the sum as 1. Then higher the ratio more synthetic points are generated for that particular point."
      ],
      "metadata": {
        "id": "Y9ECvhz4LzgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "X_over2,y_over2=SMOTE().fit_resample(X_train,y_train)\n",
        "X_over3,y_over3=ADASYN().fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "CVnv3IYSvlvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Border line smote\n",
        "\n",
        "This algorithm starts by classifying the minority class observations. It classifies any minority observation as a noise point if all the neighbors are the majority class and such an observation is ignored while creating synthetic data (Similar to DBSCAN). Further, it classifies a few points as border points that have both majority and minority class as neighborhood and resample completely from these points"
      ],
      "metadata": {
        "id": "dkwGrnkqOUaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "X_over4,y_over4=BorderlineSMOTE().fit_resample(X_train,y_train)"
      ],
      "metadata": {
        "id": "uAzNOcdQvlyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vi=[[X_train,y_train],[X_under1,y_under1],[X_under2,y_under2],[X_under3,y_under3],[X_under4,y_under4],[X_under5,y_under5],[X_under6,y_under6],[X_under7,y_under7],[X_under8,y_under8],[X_over1,y_over1],[X_over2,y_over2],[X_over3,y_over3],[X_over4,y_over4]]"
      ],
      "metadata": {
        "id": "dCcEA8s-2nce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "accuracy=[]\n",
        "recall=[]\n",
        "precision=[]\n",
        "f1=[]\n",
        "def result():\n",
        "  accuracy.append(accuracy_score(y_test,y_pred))\n",
        "  recall.append(recall_score(y_test,y_pred))\n",
        "  precision.append(precision_score(y_test,y_pred))\n",
        "  f1.append(f1_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "BQXQCSn1PUjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression"
      ],
      "metadata": {
        "id": "xCgXWcUtAnxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),LogisticRegression(random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "_S9Oedw2AfLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6299a785-e660-402c-dd18-ec924390a6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.89      0.62      0.73        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.95      0.81      0.87     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.05      0.91      0.10        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.53      0.94      0.54     56746\n",
            "weighted avg       1.00      0.97      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94     56651\n",
            "           1       0.01      0.92      0.03        95\n",
            "\n",
            "    accuracy                           0.89     56746\n",
            "   macro avg       0.51      0.90      0.48     56746\n",
            "weighted avg       1.00      0.89      0.94     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.87      0.93     56651\n",
            "           1       0.01      0.94      0.02        95\n",
            "\n",
            "    accuracy                           0.87     56746\n",
            "   macro avg       0.51      0.90      0.48     56746\n",
            "weighted avg       1.00      0.87      0.93     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.05      0.91      0.10        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.53      0.94      0.54     56746\n",
            "weighted avg       1.00      0.97      0.99     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.89      0.62      0.73        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.95      0.81      0.87     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.89      0.62      0.73        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.95      0.81      0.87     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.85      0.71      0.77        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.92      0.85      0.88     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.89      0.62      0.73        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.95      0.81      0.87     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.91      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.94      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.13      0.89      0.23        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.94      0.61     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.13      0.89      0.22        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.94      0.61     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.66      0.83      0.73        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.83      0.92      0.87     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression together with PCA taking number of component as 1,2,3"
      ],
      "metadata": {
        "id": "iOYGyvODf_TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=1),LogisticRegression(random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "yrA2qjdG7AmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9d63c3-7ea5-492b-8a51-25b0aba9443f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.15      0.82      0.25        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.91      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.15      0.81      0.26        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.58      0.90      0.63     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.11      0.81      0.19        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.55      0.90      0.59     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.15      0.82      0.25        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.91      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.13      0.82      0.23        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.91      0.61     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.83      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.91      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.83      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.91      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.35      0.81      0.48        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.67      0.90      0.74     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression(random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "9V1NV6a67Stu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcabc89-dcaf-45ac-d054-2f11a87cf26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.14      0.82      0.25        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.91      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.16      0.81      0.27        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.58      0.90      0.63     56746\n",
            "weighted avg       1.00      0.99      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.82      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.90      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.14      0.82      0.24        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.91      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.14      0.82      0.24        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.91      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.83      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.91      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.83      0.14        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.91      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.35      0.81      0.49        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.67      0.90      0.74     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=3),LogisticRegression(random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "5toJjTKY7WKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40aed623-e5b4-4ae6-dff0-5629688a0ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.14      0.84      0.25        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.92      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98     56651\n",
            "           1       0.03      0.86      0.06        95\n",
            "\n",
            "    accuracy                           0.95     56746\n",
            "   macro avg       0.52      0.91      0.52     56746\n",
            "weighted avg       1.00      0.95      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.83      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.91      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.14      0.86      0.24        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.93      0.62     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.89      0.54      0.67        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.95      0.77      0.84     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.13      0.84      0.22        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.92      0.61     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.84      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.91      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.85      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.92      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.32      0.80      0.45        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.66      0.90      0.73     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "when we have done under sampling and oversampling some of the method gives approx same matrix value as without oversampling and oversampling so oversampling and undersampling is not required here"
      ],
      "metadata": {
        "id": "Rh8aIT9rZk7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "LGtBYSvWAmDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),GaussianNB())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "_wSxFJqNPHXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd48fe5-d577-4f84-efc7-147d481c9393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.84      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.91      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     56651\n",
            "           1       0.05      0.86      0.09        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.52      0.92      0.54     56746\n",
            "weighted avg       1.00      0.97      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91     56651\n",
            "           1       0.01      0.86      0.02        95\n",
            "\n",
            "    accuracy                           0.84     56746\n",
            "   macro avg       0.50      0.85      0.47     56746\n",
            "weighted avg       1.00      0.84      0.91     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.01      0.01     56651\n",
            "           1       0.00      1.00      0.00        95\n",
            "\n",
            "    accuracy                           0.01     56746\n",
            "   macro avg       0.50      0.50      0.01     56746\n",
            "weighted avg       1.00      0.01      0.01     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.87      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.93      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.84      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.91      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.84      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.91      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.84      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.91      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.84      0.11        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.91      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.05      0.86      0.09        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.52      0.92      0.54     56746\n",
            "weighted avg       1.00      0.97      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.05      0.86      0.10        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.53      0.92      0.54     56746\n",
            "weighted avg       1.00      0.97      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.05      0.86      0.10        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.53      0.92      0.54     56746\n",
            "weighted avg       1.00      0.97      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.10      0.84      0.18        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.55      0.91      0.58     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gaussian naive bayes together with PCA taking number of component as 1,2,3 "
      ],
      "metadata": {
        "id": "d1-OmHT1grEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=1),GaussianNB())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "mt5Qt0Wi8Xpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a31f8b-0c34-4829-e90b-464620b78b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.10      0.81      0.17        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.55      0.90      0.58     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.05      0.83      0.10        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.53      0.90      0.54     56746\n",
            "weighted avg       1.00      0.97      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97     56651\n",
            "           1       0.03      0.81      0.05        95\n",
            "\n",
            "    accuracy                           0.95     56746\n",
            "   macro avg       0.51      0.88      0.51     56746\n",
            "weighted avg       1.00      0.95      0.97     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.14      0.81      0.23        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.57      0.90      0.61     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.12      0.81      0.21        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.90      0.60     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.12      0.81      0.21        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.90      0.60     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.12      0.81      0.21        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.90      0.60     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.38      0.80      0.51        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.69      0.90      0.76     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=2),GaussianNB())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "W02rP3od8hg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b200d40-be98-4574-d9ea-1579d614a8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.81      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     56651\n",
            "           1       0.04      0.82      0.08        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.52      0.89      0.53     56746\n",
            "weighted avg       1.00      0.97      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98     56651\n",
            "           1       0.03      0.81      0.06        95\n",
            "\n",
            "    accuracy                           0.95     56746\n",
            "   macro avg       0.51      0.88      0.52     56746\n",
            "weighted avg       1.00      0.95      0.97     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.11      0.81      0.19        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.55      0.90      0.59     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.09      0.81      0.16        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.54      0.90      0.58     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.09      0.81      0.16        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.08      0.81      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.18      0.80      0.29        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.59      0.90      0.64     56746\n",
            "weighted avg       1.00      0.99      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=3),GaussianNB())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "ineMdamN8hkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4f7311-8184-4cba-fdc1-5a5051826a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.01      0.03      0.02        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.50      0.51      0.51     56746\n",
            "weighted avg       1.00      0.99      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.08      0.81      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     56651\n",
            "           1       0.03      0.82      0.06        95\n",
            "\n",
            "    accuracy                           0.96     56746\n",
            "   macro avg       0.52      0.89      0.52     56746\n",
            "weighted avg       1.00      0.96      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.56      0.71     56651\n",
            "           1       0.00      0.92      0.01        95\n",
            "\n",
            "    accuracy                           0.56     56746\n",
            "   macro avg       0.50      0.74      0.36     56746\n",
            "weighted avg       1.00      0.56      0.71     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.11      0.81      0.20        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.90      0.60     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.05      0.18      0.08        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.53      0.59      0.54     56746\n",
            "weighted avg       1.00      0.99      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.01      0.03      0.01        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.50      0.51      0.50     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.85      0.81      0.83        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.92      0.91      0.91     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.01      0.05      0.02        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.51      0.52      0.51     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.09      0.81      0.16        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.09      0.81      0.16        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     56651\n",
            "           1       0.08      0.81      0.15        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.54      0.90      0.57     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.12      0.81      0.21        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.56      0.90      0.60     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for Gaussian Naive Bayes algorithm imbalanced data give very bad prediction as we can see from recall and precision value so here under sampling and over sampling is required"
      ],
      "metadata": {
        "id": "GunJ_GpV71l4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision-Tree algorithm"
      ],
      "metadata": {
        "id": "Ed1-ubYrA4PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),DecisionTreeClassifier(criterion='entropy', random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyaB0mXpA3Bh",
        "outputId": "3908f839-e7cb-4760-f196-532bc4694b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.75      0.83      0.79        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.87      0.92      0.89     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95     56651\n",
            "           1       0.02      1.00      0.03        95\n",
            "\n",
            "    accuracy                           0.91     56746\n",
            "   macro avg       0.51      0.95      0.49     56746\n",
            "weighted avg       1.00      0.91      0.95     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.76      0.87     56651\n",
            "           1       0.01      0.87      0.01        95\n",
            "\n",
            "    accuracy                           0.76     56746\n",
            "   macro avg       0.50      0.82      0.44     56746\n",
            "weighted avg       1.00      0.76      0.86     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.06      0.12     56651\n",
            "           1       0.00      1.00      0.00        95\n",
            "\n",
            "    accuracy                           0.07     56746\n",
            "   macro avg       0.50      0.53      0.06     56746\n",
            "weighted avg       1.00      0.07      0.12     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95     56651\n",
            "           1       0.02      0.89      0.03        95\n",
            "\n",
            "    accuracy                           0.91     56746\n",
            "   macro avg       0.51      0.90      0.49     56746\n",
            "weighted avg       1.00      0.91      0.95     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.75      0.83      0.79        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.87      0.92      0.89     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.75      0.83      0.79        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.87      0.92      0.89     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.47      0.80      0.60        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.74      0.90      0.80     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.75      0.78      0.76        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.87      0.89      0.88     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.79      0.81      0.80        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.90      0.91      0.90     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.48      0.85      0.61        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.74      0.93      0.81     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.42      0.84      0.56        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.71      0.92      0.78     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.77      0.78      0.77        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.89      0.89      0.89     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "decision tree classifier togethetr with PCA  taking component as  1,2,3"
      ],
      "metadata": {
        "id": "KViBMzXSgwTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=1),DecisionTreeClassifier(criterion='entropy', random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "f6pRzhzA9itp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0d66764-d27d-44c8-aa72-111ee0266f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92     56651\n",
            "           1       0.01      1.00      0.02        95\n",
            "\n",
            "    accuracy                           0.85     56746\n",
            "   macro avg       0.51      0.92      0.47     56746\n",
            "weighted avg       1.00      0.85      0.92     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91     56651\n",
            "           1       0.01      0.86      0.02        95\n",
            "\n",
            "    accuracy                           0.84     56746\n",
            "   macro avg       0.50      0.85      0.47     56746\n",
            "weighted avg       1.00      0.84      0.91     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.79      0.88     56651\n",
            "           1       0.01      0.81      0.01        95\n",
            "\n",
            "    accuracy                           0.79     56746\n",
            "   macro avg       0.50      0.80      0.45     56746\n",
            "weighted avg       1.00      0.79      0.88     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.01      0.02      0.01        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.51      0.51     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.00      0.00      0.00        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.50      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.71      0.66      0.68        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.85      0.83      0.84     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95     56651\n",
            "           1       0.01      0.85      0.03        95\n",
            "\n",
            "    accuracy                           0.90     56746\n",
            "   macro avg       0.51      0.87      0.49     56746\n",
            "weighted avg       1.00      0.90      0.94     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.89      0.94     56651\n",
            "           1       0.01      0.85      0.03        95\n",
            "\n",
            "    accuracy                           0.89     56746\n",
            "   macro avg       0.51      0.87      0.49     56746\n",
            "weighted avg       1.00      0.89      0.94     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     56651\n",
            "           1       0.15      0.82      0.26        95\n",
            "\n",
            "    accuracy                           0.99     56746\n",
            "   macro avg       0.58      0.91      0.63     56746\n",
            "weighted avg       1.00      0.99      0.99     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=2),DecisionTreeClassifier(criterion='entropy', random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "nVDbPhy79tHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3ef819-fe5b-4806-c3e0-f843e65a49f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.04      0.04      0.04        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.52      0.52      0.52     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91     56651\n",
            "           1       0.01      1.00      0.02        95\n",
            "\n",
            "    accuracy                           0.84     56746\n",
            "   macro avg       0.51      0.92      0.47     56746\n",
            "weighted avg       1.00      0.84      0.91     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.81      0.89     56651\n",
            "           1       0.01      0.86      0.01        95\n",
            "\n",
            "    accuracy                           0.81     56746\n",
            "   macro avg       0.50      0.84      0.45     56746\n",
            "weighted avg       1.00      0.81      0.89     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.64      0.78     56651\n",
            "           1       0.00      0.89      0.01        95\n",
            "\n",
            "    accuracy                           0.64     56746\n",
            "   macro avg       0.50      0.77      0.39     56746\n",
            "weighted avg       1.00      0.64      0.78     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92     56651\n",
            "           1       0.01      0.83      0.02        95\n",
            "\n",
            "    accuracy                           0.85     56746\n",
            "   macro avg       0.50      0.84      0.47     56746\n",
            "weighted avg       1.00      0.85      0.92     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.02      0.02      0.02        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.51      0.51      0.51     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.04      0.04      0.04        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.52      0.52      0.52     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.03      0.05      0.04        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.51      0.52      0.52     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.01      0.01      0.01        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.51      0.50      0.50     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.78      0.73      0.75        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.89      0.86      0.88     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96     56651\n",
            "           1       0.02      0.84      0.04        95\n",
            "\n",
            "    accuracy                           0.93     56746\n",
            "   macro avg       0.51      0.89      0.50     56746\n",
            "weighted avg       1.00      0.93      0.96     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96     56651\n",
            "           1       0.02      0.82      0.04        95\n",
            "\n",
            "    accuracy                           0.93     56746\n",
            "   macro avg       0.51      0.88      0.50     56746\n",
            "weighted avg       1.00      0.93      0.96     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.33      0.80      0.47        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.67      0.90      0.73     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=3),DecisionTreeClassifier(criterion='entropy', random_state=0))\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "Klu2x9L79tKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdee3279-d1b2-4f37-9667-2afd5383b527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.19      0.16      0.17        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.60      0.58      0.59     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92     56651\n",
            "           1       0.01      1.00      0.02        95\n",
            "\n",
            "    accuracy                           0.85     56746\n",
            "   macro avg       0.51      0.92      0.47     56746\n",
            "weighted avg       1.00      0.85      0.92     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90     56651\n",
            "           1       0.01      0.87      0.02        95\n",
            "\n",
            "    accuracy                           0.82     56746\n",
            "   macro avg       0.50      0.85      0.46     56746\n",
            "weighted avg       1.00      0.82      0.90     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.38      0.56     56651\n",
            "           1       0.00      0.94      0.01        95\n",
            "\n",
            "    accuracy                           0.39     56746\n",
            "   macro avg       0.50      0.66      0.28     56746\n",
            "weighted avg       1.00      0.39      0.55     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92     56651\n",
            "           1       0.01      0.88      0.02        95\n",
            "\n",
            "    accuracy                           0.85     56746\n",
            "   macro avg       0.50      0.87      0.47     56746\n",
            "weighted avg       1.00      0.85      0.92     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.06      0.05      0.05        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.53      0.53      0.53     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.06      0.05      0.05        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.53      0.53      0.53     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.64      0.80      0.71        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.82      0.90      0.85     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.15      0.15      0.15        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.57      0.57      0.57     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.76      0.74      0.75        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.88      0.87      0.87     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.06      0.83      0.12        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.91      0.55     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56651\n",
            "           1       0.07      0.82      0.12        95\n",
            "\n",
            "    accuracy                           0.98     56746\n",
            "   macro avg       0.53      0.90      0.56     56746\n",
            "weighted avg       1.00      0.98      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.59      0.77      0.67        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.80      0.88      0.83     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for Decision-Tree algorithm some oversampling method gives very bad prediction here without applying oversampling and undersampling algorithm it give good prediction"
      ],
      "metadata": {
        "id": "D0NFTZqW9DM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "random forest and pca tking component as 1,2,3"
      ],
      "metadata": {
        "id": "ABiUBkAShb44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipe = make_pipeline(StandardScaler(),RandomForestClassifier())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "QynETpkwPHqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cf7059-a22b-437c-84ca-3a6b8232b221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.99      0.82      0.90        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.99      0.91      0.95     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56651\n",
            "           1       0.06      1.00      0.11        95\n",
            "\n",
            "    accuracy                           0.97     56746\n",
            "   macro avg       0.53      0.99      0.55     56746\n",
            "weighted avg       1.00      0.97      0.99     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91     56651\n",
            "           1       0.01      0.94      0.02        95\n",
            "\n",
            "    accuracy                           0.84     56746\n",
            "   macro avg       0.50      0.89      0.46     56746\n",
            "weighted avg       1.00      0.84      0.91     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.04      0.07     56651\n",
            "           1       0.00      1.00      0.00        95\n",
            "\n",
            "    accuracy                           0.04     56746\n",
            "   macro avg       0.50      0.52      0.04     56746\n",
            "weighted avg       1.00      0.04      0.07     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     56651\n",
            "           1       0.04      0.91      0.07        95\n",
            "\n",
            "    accuracy                           0.96     56746\n",
            "   macro avg       0.52      0.93      0.53     56746\n",
            "weighted avg       1.00      0.96      0.98     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.97      0.82      0.89        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.99      0.91      0.95     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.97      0.81      0.89        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.99      0.91      0.94     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56651\n",
            "           1       0.98      0.83      0.90        95\n",
            "\n",
            "    accuracy                           1.00     56746\n",
            "   macro avg       0.99      0.92      0.95     56746\n",
            "weighted avg       1.00      1.00      1.00     56746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=1),RandomForestClassifier())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "AVL9FUb0-6gq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "da909598-483c-4cdb-f4e9-ebd271b6e895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5894c6bfb59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=2),RandomForestClassifier())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "iKvPxuFp-6kw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "4c9d4690-b12f-4eb2-8249-c8af2e63f83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-36f3fe3327a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipe = make_pipeline(StandardScaler(),PCA(n_components=3),RandomForestClassifier())\n",
        "for i in range(len(vi)):\n",
        "  pipe.fit(vi[i][0],vi[i][1])\n",
        "  y_pred=pipe.predict(X_test)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  result()"
      ],
      "metadata": {
        "id": "3780uQ4e-6n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame({'accuracy':accuracy,'recall':recall,'f1 score':f1,'precision':precision})"
      ],
      "metadata": {
        "id": "U2wqAzt_-6re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEq6R8PDxgPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}